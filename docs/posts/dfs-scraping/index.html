<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-03-26">

<title>Ethan Orlowsky - Just scraping by</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../img/eio_logo_white.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../../css/styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../img/eio_logo_white.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Ethan Orlowsky</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Ethor13"><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/EthanOrlowsky"><i class="bi bi-twitter" role="img" aria-label="Twitter">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/ethan-orlowsky/"><i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Just scraping by</h1>
            <p class="subtitle lead">Webscraping techniques to overcome difficult websites</p>
                                <div class="quarto-categories">
                <div class="quarto-category">daily fantasy sports</div>
                <div class="quarto-category">webscraping</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 26, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>In the first blog post of the Riddler’s development, I want to talk about webscraping. The logical first step of Riddler was to collect data from Draft Kings. This data is a prerequisite for testing the performance of the lineup generation algorithm. To illustrate the dynamics of this project, I created a visualization below that captures some of the key processes.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
<svg width="672" height="480" viewbox="0.00 0.00 417.92 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>
G
</title>
<!-- Contest Info -->
<g id="node1" class="node">
<title>
Contest Info
</title>
<ellipse fill="none" stroke="white" cx="85.46" cy="-162" rx="59.1" ry="18"></ellipse> <text text-anchor="middle" x="85.46" y="-157.8" font-family="circular-spotify" font-size="14.00" fill="white">Contest Info</text> </g> <!-- Riddler --> <g id="node2" class="node">
<title>
Riddler
</title>
<ellipse fill="none" stroke="white" cx="216.46" cy="-90" rx="40.01" ry="18"></ellipse> <text text-anchor="middle" x="216.46" y="-85.8" font-family="circular-spotify" font-size="14.00" fill="white">Riddler</text> </g> <!-- Contest Info&#45;&gt;Riddler --> <g id="edge1" class="edge">
<title>
Contest Info-&gt;Riddler
</title>
<path fill="none" stroke="white" d="M113.56,-145.98C133.73,-135.21 161.02,-120.62 182.43,-109.19"></path> <polygon fill="white" stroke="white" points="184.33,-112.14 191.5,-104.34 181.03,-105.96 184.33,-112.14"></polygon> </g> <!-- Lineup #1 --> <g id="node5" class="node">
<title>
Lineup #1
</title>
<ellipse fill="none" stroke="white" cx="50.46" cy="-18" rx="50.42" ry="18"></ellipse> <text text-anchor="middle" x="50.46" y="-13.8" font-family="circular-spotify" font-size="14.00" fill="white">Lineup #1</text> </g> <!-- Riddler&#45;&gt;Lineup #1 --> <g id="edge4" class="edge">
<title>
Riddler-&gt;Lineup #1
</title>
<path fill="none" stroke="white" d="M188.3,-77.13C161.68,-65.9 121.42,-48.92 91.28,-36.21"></path> <polygon fill="white" stroke="white" points="92.45,-32.91 81.88,-32.25 89.73,-39.36 92.45,-32.91"></polygon> </g> <!-- Lineup #2 --> <g id="node6" class="node">
<title>
Lineup #2
</title>
<ellipse fill="none" stroke="white" cx="169.46" cy="-18" rx="50.42" ry="18"></ellipse> <text text-anchor="middle" x="169.46" y="-13.8" font-family="circular-spotify" font-size="14.00" fill="white">Lineup #2</text> </g> <!-- Riddler&#45;&gt;Lineup #2 --> <g id="edge5" class="edge">
<title>
Riddler-&gt;Lineup #2
</title>
<path fill="none" stroke="white" d="M205.32,-72.41C199.73,-64.08 192.82,-53.8 186.57,-44.49"></path> <polygon fill="white" stroke="white" points="189.33,-42.31 180.85,-35.96 183.51,-46.21 189.33,-42.31"></polygon> </g> <!-- ... --> <g id="node7" class="node">
<title>
…
</title>
<ellipse fill="none" stroke="white" stroke-width="0" cx="264.46" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="264.46" y="-13.8" font-family="circular-spotify" font-size="14.00" fill="white">…</text> </g> <!-- Riddler&#45;&gt;... --> <g id="edge6" class="edge">
<title>
Riddler-&gt;…
</title>
<path fill="none" stroke="white" d="M227.84,-72.41C233.78,-63.74 241.17,-52.97 247.75,-43.38"></path> <polygon fill="white" stroke="white" points="250.73,-45.21 253.5,-34.99 244.96,-41.26 250.73,-45.21"></polygon> </g> <!-- Lineup #3 --> <g id="node8" class="node">
<title>
Lineup #3
</title>
<ellipse fill="none" stroke="white" cx="359.46" cy="-18" rx="50.42" ry="18"></ellipse> <text text-anchor="middle" x="359.46" y="-13.8" font-family="circular-spotify" font-size="14.00" fill="white">Lineup #3</text> </g> <!-- Riddler&#45;&gt;Lineup #3 --> <g id="edge7" class="edge">
<title>
Riddler-&gt;Lineup #3
</title>
<path fill="none" stroke="white" d="M242.69,-76.16C264.85,-65.31 296.88,-49.64 321.78,-37.44"></path> <polygon fill="white" stroke="white" points="323.5,-40.5 330.95,-32.96 320.43,-34.21 323.5,-40.5"></polygon> </g> <!-- Player Info --> <g id="node3" class="node">
<title>
Player Info
</title>
<ellipse fill="none" stroke="white" cx="216.46" cy="-162" rx="54.42" ry="18"></ellipse> <text text-anchor="middle" x="216.46" y="-157.8" font-family="circular-spotify" font-size="14.00" fill="white">Player Info</text> </g> <!-- Player Info&#45;&gt;Riddler --> <g id="edge2" class="edge">
<title>
Player Info-&gt;Riddler
</title>
<path fill="none" stroke="white" d="M216.46,-143.7C216.46,-135.98 216.46,-126.71 216.46,-118.11"></path> <polygon fill="white" stroke="white" points="219.96,-118.1 216.46,-108.1 212.96,-118.1 219.96,-118.1"></polygon> </g> <!-- Bankroll --> <g id="node4" class="node">
<title>
Bankroll
</title>
<ellipse fill="none" stroke="white" cx="333.46" cy="-162" rx="44.66" ry="18"></ellipse> <text text-anchor="middle" x="333.46" y="-157.8" font-family="circular-spotify" font-size="14.00" fill="white">Bankroll</text> </g> <!-- Bankroll&#45;&gt;Riddler --> <g id="edge3" class="edge">
<title>
Bankroll-&gt;Riddler
</title>
<path fill="none" stroke="white" d="M309.5,-146.67C291.84,-136.1 267.64,-121.62 248.34,-110.07"></path> <polygon fill="white" stroke="white" points="249.97,-106.97 239.59,-104.84 246.38,-112.98 249.97,-106.97"></polygon> </g> </g>
</svg>
</p>
</div>
</div>
</div>
<p>By scraping Draft Kings, we can check off the “Contest Info” box. There is a lot of useful information we can obtain from their website, including:</p>
<ul>
<li>Contest Types</li>
<li>Number of Partipants per Contest</li>
<li>Draftable Players and their Salary</li>
<li>Contest Payout Structure</li>
<li>Maximum Entries per Contest</li>
</ul>
<p>If you navigate through the <a href="https://www.draftkings.com/lobby#/NBA">Draft Kings Lobby</a>, you can easily find all this information for any contest.</p>
<section id="my-first-attempt" class="level2">
<h2 class="anchored" data-anchor-id="my-first-attempt">My First Attempt</h2>
<p>I was inspired to automate the contest information collection process using familiar webscraping techniques, like <a href="https://requests.readthedocs.io/en/latest/">Requests</a> and <a href="https://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a>. However, upon my first iterations of scraping, I discovered these methods would not work well for my problem due to authentication requirements, and the volume of requests I needed to make. On certain parts of the website, I needed to send in cookies to prove that I had an account. While you can send cookies with the requests package, my problem was having cookies always ready. There were many session cookies that would expire within 24 hours, so I couldn’t just do this step manually once and call it a day. Additionally, there are on the scale of thousands of contests per day, and I needed to request information about each one. If I were to make requests sequentially, this scraping method would take a very long time, whereas I wanted it to take at most a couple minutes.</p>
</section>
<section id="solving-the-authentication-issue" class="level2">
<h2 class="anchored" data-anchor-id="solving-the-authentication-issue">Solving the Authentication Issue</h2>
<p>To get cookies from the browser, you need to simulate the browser. Simulating the browser means having your program open up an instance of your browser, and clicking on certain buttons and typing into text boxes the way you normally would. Luckily, <a href="https://www.selenium.dev/">Selenium</a> allows you to do just that. The idea behind Selenium is that you can navigate a website by specifying which HTML elements to interact with. You can do this by providing tags, classes, ids, xpaths, or something else. In my case I opened up a browser automatically with Selenium and was looking at this page:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/dk_login.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">DraftKings Login Page</figcaption><p></p>
</figure>
</div>
<p>My goal is to type my credentials into the Username and Password boxes. The first thing I need to do is tell Selenium which HTML element to interact with. I can find the element in the HTML document by right-clicking on it and pressing inspect. Now to find a description of this element, right-click on it in the HTML document and hover over the copy tab and click on any of the options. Clicking on selector in this case identifies the Username box as #login-username-input and the Password box as #login-password-input. Now I can tell Selenium to type my Username and Password into these elements, and finally click the Log In button. To get an idea of how it looks in Selenium, here is a snippet doing what I just described.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> login(driver):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    username <span class="op">=</span> driver.find_element(By.ID, <span class="st">"login-username-input"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    password <span class="op">=</span> driver.find_element(By.ID, <span class="st">"login-password-input"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    submit <span class="op">=</span> driver.find_element(By.ID, <span class="st">"login-submit"</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    username.send_keys(os.getenv(<span class="st">"DK_USERNAME"</span>))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    password.send_keys(os.getenv(<span class="st">"DK_PASSWORD"</span>))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    submit.submit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For the full implementation, check out this <a href="https://github.com/Ethor13/draft-kings-db/blob/main/scripts/python/selenium_scraper.py">Python Script</a> in my GitHub Repo.</p>
<p>Now that we are logged in, we can retrieve the cookies from the browser and save them for later when we scrape contest data. We initially get the cookies in a dictionary, but depending on the tools you use later, you might want to store them differently. In my case, I needed the cookies in the Netscape cookies format because I was using the <a href="https://man7.org/linux/man-pages/man1/wget.1.html">wget</a> command. So, I wrote a utility function that converted the cookies to the desired format and wrote them to a file. Since Selenium is slow compared to other scraping tools that don’t automate the web broswer, we won’t be using Selenium again for speed purposes. But depending on your application, you could very well use Selenium for the rest of your webscraping project.</p>
</section>
<section id="solving-the-speed-issue" class="level2">
<h2 class="anchored" data-anchor-id="solving-the-speed-issue">Solving the Speed Issue</h2>
<p>As I mentioned before, processing a large number of sequential web requests is not a viable long term solution. Trying to retrieve a simple page like <a href="https://www.google.com">www.google.com</a> can take half a second, which done 3,000 times in a row would guarantee a runtime of at least 25 minutes. So, we turn to <a href="https://man7.org/linux/man-pages/man1/xargs.1.html">xargs</a> to parallelize this process. The entire <code>xargs</code> command is pretty beefy, so it wouldn’t be of much help to look at directly, so I’ll explain part by part, and you can refer to the full commands for <a href="https://github.com/Ethor13/draft-kings-db/blob/main/scripts/shell/download_standings.sh">downloading standings</a> and <a href="https://github.com/Ethor13/draft-kings-db/blob/main/scripts/shell/download_payouts.sh">downloading payouts</a>. First, we need to understand how <code>wget</code> works. Here are the relevant flags and what they do:</p>
<table class="table">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 54%">
</colgroup>
<thead>
<tr class="header">
<th>Flag</th>
<th>Argument</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>–content-disposition</td>
<td>none</td>
<td>Sets the name of the file to what it was on the server</td>
</tr>
<tr class="even">
<td>–load-cookies</td>
<td>netscape cookies file</td>
<td>Load cookies from a file</td>
</tr>
<tr class="odd">
<td>-o</td>
<td>log file</td>
<td>Log the results of the command for debugging</td>
</tr>
<tr class="even">
<td>–input-file</td>
<td>urls file</td>
<td>Scrape many sites with one wget call</td>
</tr>
<tr class="odd">
<td>-U</td>
<td>user agent string</td>
<td>The user agent to use for the batch of requests</td>
</tr>
</tbody>
</table>
<p>So within one <code>wget</code> call we are scraping as many sites as are in the input file. It’s good to batch the urls together because it saves time by only initializing (i.e.&nbsp;loading cookies, creating log file) once, but not too much in order to maximize the benefits of parallelization later with <code>xargs</code>. I put 50 urls in each file. Note that nothing so far is parallelized. Each of the urls in the input file will be retrieved sequentially.</p>
<p>Parallelization comes in when we call this <code>wget</code> command within an <code>xargs</code> command. This will look something like <code>xargs ... wget ...</code> where the dots are flags and arguments to the command that comes before it. The flags that allow the command to be run in parallel are discussed below:</p>
<table class="table">
<thead>
<tr class="header">
<th>Flag</th>
<th>Argument</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-L</td>
<td>max lines</td>
<td>How many lines to read at a time from input</td>
</tr>
<tr class="even">
<td>-P</td>
<td>max processes</td>
<td>How many processes to run at a time</td>
</tr>
</tbody>
</table>
<p>Notice that the <code>-L</code> flag implies that we’re reading from input. What we are reading from input is a list of input files to later pass into <code>wget</code>. In our case, our flags were <code>-L 1 -P 10</code> implying that we read one input file at a time, and run 10 processes in parallel. In this context, a process is a separate invocation of <code>wget</code>. So the speed-up happens because we have 10 <code>wget</code> processes running at the same time, which should make our scraping take about one tenth of the time. While we could go even faster by increasing the number of processes, I didn’t want to be a nuisance and flood DraftKings more than I already am.</p>
</section>
<section id="putting-it-all-together" class="level2">
<h2 class="anchored" data-anchor-id="putting-it-all-together">Putting it all Together</h2>
<p>Now that I had written and tested a successful scraper, I had to automate the process of running the script everyday. To do this I created a scheduled task to run a master script that included all the scraping commands on my computer everyday at 6am. I’m based on a Windows machine, so I used Task Scheduler, but there’s equivalent tools to do this for MacOS and Linux users as well.</p>
<p>Typically, this is good enough. But, I was concerned that sometimes my computer might not run the script for whatever reason (i.e.&nbsp;the computer is dead, or I’m travelling and not connected to the internet at 6am). To make me feel better about this data collection, I wanted to make the data collection redundant. And I also didn’t want to setup some program on AWS that would inevitably bankrupt me. So, I turned to GitHub Actions.</p>
<p>Actions are a great way to automate running code. The general idea is that you can create a YAML file with instructions of what to do and GitHub will follow those exact instructions provided you place it in the <code>.github/workflows/</code> directory. You can find my workflow <a href="https://github.com/Ethor13/draft-kings-db/blob/main/.github/workflows/scrape.yml">here</a>.</p>
<p>Here are some highlights of the workflow that will help to understand the capabilities of Actions so you know what kinds of problems it is good at solving.</p>
<section id="run-the-code-once-daily-at-6am-est-10-am-utc" class="level3">
<h3 class="anchored" data-anchor-id="run-the-code-once-daily-at-6am-est-10-am-utc">Run the code once daily at 6am EST (10 am UTC)</h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">on</span><span class="kw">:</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">schedule</span><span class="kw">:</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="fu">cron</span><span class="kw">:</span><span class="at"> </span><span class="st">"0 10 * * *"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Cron jobs are a popular way to schedule tasks on unix-based operating systems. You can review the syntax for <a href="https://crontab.guru/examples.html">cron scheduling</a> to know how to achieve the schedule you want.</p>
</section>
<section id="cache-the-python-environment-so-you-can-use-the-same-one-again-tomorrow" class="level3">
<h3 class="anchored" data-anchor-id="cache-the-python-environment-so-you-can-use-the-same-one-again-tomorrow">Cache the Python Environment so you can use the same one again tomorrow</h3>
<div class="sourceCode" id="cb3"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> Checkout repo</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">uses</span><span class="kw">:</span><span class="at"> actions/checkout@master</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> Set up Python</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">uses</span><span class="kw">:</span><span class="at"> actions/setup-python@v4</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">with</span><span class="kw">:</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">python-version</span><span class="kw">:</span><span class="at"> </span><span class="st">"3.11"</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> Cache Python Environment</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">uses</span><span class="kw">:</span><span class="at"> actions/cache@v3</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">with</span><span class="kw">:</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">path</span><span class="kw">:</span><span class="at"> ${{ env.pythonLocation }}</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">key</span><span class="kw">:</span><span class="at"> ${{ env.pythonLocation }}-${{ hashFiles('setup.py') }}-${{ hashFiles('requirements.txt') }}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Everytime you run an Action, you start off with a fresh virtual machine. If you want to use Python, you will have to download it fresh each time, which means you don’t have your packages that you used from last time. Downloading packages can take a really long time, so to avoid this delay, you can cache your python environments and packages so you can reuse what you have downloaded before.</p>
</section>
<section id="run-python-scripts" class="level3">
<h3 class="anchored" data-anchor-id="run-python-scripts">Run Python Scripts</h3>
<div class="sourceCode" id="cb4"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> Scrape Contests</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">run</span><span class="kw">:</span><span class="at"> python scripts/python/scrape_contests.py</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Each time you specify a run command in YAML, you get direct access to the command-line. You can use this as you would on your machine and directly run a python script. It’s as easy as that.</p>
</section>
<section id="drawbacks" class="level3">
<h3 class="anchored" data-anchor-id="drawbacks">Drawbacks</h3>
<p>The only drawback I found with GitHub Actions so far is that I could not get selenium working properly. The issue had to do with the provided VM not having an external display, so the browser emulation could not fool DraftKings into thinking it was human on the website, and not a bot. This means that only some of the data is being scraped by GitHub each day. The silver-lining is that the data it scrapes can be used to fetch the missing parts on my machine locally if there’s ever a scenario that requires it.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>If you’re new to webscraping, I hope you were able to learn a thing or two. One thing that you will learn if you haven’t already is that webscraping is always an arduous task, as no two websites are the same and there’s no one-size-fits-all solution. Webscraping is definitely an acquired taste, but it’s well worth its weight in data.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>