[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ethan Orlowsky",
    "section": "",
    "text": "Posts\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\nRiddle me this\n\n\nan Introduction to a DFS Lineup Generating Algorithm\n\n\n\n\ndaily fantasy sports\n\n\n \n\n\n\n\nFeb 10, 2023\n\n\n7 min\n\n\n\n\n\n\n\n\nExtreme Couponing\n\n\nCoupon Collector’s Problem Generalized to K sets of coupons\n\n\n\n\nprobability\n\n\n \n\n\n\n\nJan 23, 2023\n\n\n11 min\n\n\n\n\n\n\n\n\nResearch Archives\n\n\nThings I found interesting\n\n\n\n\nmisc\n\n\n \n\n\n\n\nJan 1, 2023\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/coupon-collector/index.html",
    "href": "posts/coupon-collector/index.html",
    "title": "Extreme Couponing",
    "section": "",
    "text": "The traditional coupon collector’s problem asks the following question:\n\nIf there are n different kinds of coupons, and all coupons have the same probability of being drawn, how many coupons do you expect to draw with replacement to collect all kinds of coupons?\n\nWikipedia has a good explanation, so I will use that as a template for my calculation.\nLet \\(T\\) be the random variable representing the number of coupons we draw before collecting the entire set of coupons. We can decompose \\(T\\) into the sum of \\(n\\) random variables, \\(t_i\\), where \\(t_i\\) is the number of coupons drawn to get the \\(i^{th}\\) distinct coupon after \\(i - 1\\) distinct coupons have already been drawn.\n\\[\\begin{align*}\n    T = t_1 + t_2 + \\ldots + t_n\n\\end{align*}\\]\n\n\n\n\n\n\nNote\n\n\n\nA common mistake is to decompose \\(T\\) into random variables \\(t_i\\), where \\(t_i\\) represents the number of coupons drawn to collect coupon #\\(i\\).\nThis is incorrect because we are likely going to be double-counting coupon draws. Let’s look at a simple example where \\(n = 2\\), and we draw coupon #\\(1\\), then coupon #\\(2\\). This method would set \\(t_1 = 1\\), \\(t_2 = 2\\), and \\(T = 3\\). Obviously this isn’t correct, but it’s easily mistakable when you haven’t seen the right way to approach the problem first.\n\n\nUsing Linearity of Expectation, we can separate our problem into simpler subproblems.\n\\[\\begin{align*}\n    E[T]\n    &= E[t_1 + t_2 + \\ldots + t_n] \\\\\n    &= E[t_1] + E[t_2] + \\ldots + E[t_n]\n\\end{align*}\\]\nNow the problem is finding what the general solution is for a number of the form \\(E[t_i]\\). \\(E[t_i]\\) captures the expected number of coupon draws to get the \\(i^{th}\\) distinct coupon after \\(i - 1\\) distinct coupons have already been drawn. We know that if \\(i - 1\\) out of \\(n\\) coupons have been drawn already, there are \\(n - i + 1\\) remaining coupons we still need to draw. So the probability we draw a new coupon is \\(\\frac{n - i + 1}{n}\\). \\(t_i\\) is satisfied on the first such success, so it has a Geometric Distribution. The expected value of a geometric random variable is \\(\\frac{1}{p}\\), or in our case, \\(\\frac{n}{n - i + 1}\\). We can now go back and solve for \\(E[T]\\).\n\\[\\begin{align*}\n    E[T]\n    &= E[t_1 + t_2 + \\ldots + t_n] \\\\\n    &= E[t_1] + E[t_2] + \\ldots + E[t_n] \\\\\n    &= \\frac{n}{n} + \\frac{n}{n - 1} + \\ldots + \\frac{n}{1} \\\\\n    &= n \\left( \\frac{1}{1} + \\frac{1}{2} + \\ldots + \\frac{1}{n} \\right) \\\\\n    &= n H_n\n\\end{align*}\\]\nwhere \\(H_n\\) is the \\(n^{th}\\) Harmonic Number. The harmonic numbers don’t have a closed form solution, but we can easily calculate them for small enough \\(N\\). We can visualize our solution using Python.\n\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nN = 50\n\ndef harmonic(n):\n    return sum(1 / i for i in range(1, n + 1))\n\nexpectations = [n * harmonic(n) for n in range(N)]\n\nplt.plot(range(1, N + 1), expectations)\nplt.gca().set(title=\"Coupon Collector's Problem\",\n              xlabel='N', \n              ylabel='Expected Draws')\nplt.show()"
  },
  {
    "objectID": "posts/coupon-collector/index.html#generalizing-to-k-sets-of-coupons",
    "href": "posts/coupon-collector/index.html#generalizing-to-k-sets-of-coupons",
    "title": "Extreme Couponing",
    "section": "Generalizing to K sets of Coupons",
    "text": "Generalizing to K sets of Coupons\nA natural extension to this warmup is asking how things change when we need to collect K of each coupon. Unfortunately, we need to take a completely different approach than we did for the case of \\(K = 1\\). We must now leverage combinatorics.\nFirst, let’s define a few terms. We are trying to find the expected number of coupons we must draw before getting \\(K\\) of each, or \\(E_K[T]\\). \\(T\\) takes on integer values, so we can rewrite our expectation as:\n\\[\\begin{align*}\n    E_K[T]\n    &= \\sum_{i=0}^\\infty i \\cdot P(T = i) \\\\\n    &= P(T = 1) + 2 \\cdot P(T = 2) + 3 \\cdot P(T = 3) + \\ldots \\\\\n    &= P(T = 1) + P(T = 2) + P(T = 3) + \\ldots \\\\\n    & \\hspace{54pt} + P(T = 2) + P(T = 3) + \\ldots \\\\\n    & \\hspace{107pt} + P(T = 3) + \\ldots \\\\\n    & \\hspace{160pt} + \\ldots \\\\\n    &= P(T > 0) + P(T > 1) + P(T > 2) + \\ldots \\\\\n    &= \\sum_{i = 0}^\\infty P(T > i) \\\\\n    &= \\sum_{i = 0}^\\infty p_i\n\\end{align*}\\]\nwhere \\(p_i = P(T > i)\\). The interpretation of \\(p_i\\) is the probability that we fail to collect \\(K\\) complete sets in \\(i\\) draws. Since there are \\(n\\) different kinds of coupons, there are \\(n^i\\) ways to draw \\(i\\) coupons. All the possible ways to draw these coupons can be represented as the polynomial:\n\\[\\begin{align*}\n    (x_1 + \\ldots + x_n)^i\n\\end{align*}\\]\nIf we were to expand this polynomial, each term would represent a combination of possible draws. For example, one of the terms in the expansion would be \\(x_1^3x_5x_9^7x_{12}^{i - 11}\\). This term represents the event of pulling 3 of coupon #1, 1 of coupon #5, 7 of coupon #9, and the remaining \\(i - 11\\) being coupon #12. Of course there are multiple ways (permutations) to pull this combination of coupons, so there would also be a coefficient on the term indicating how many ways this can be done.\n\n\n\n\n\n\nNote\n\n\n\nThough not core to the problem at hand, we can quickly discuss what that coefficient would be. Sticking with our previous example of \\(x_1^3x_5x_9^7x_{12}^{i - 11}\\), we start by thinking about how we can assign an order for these given amounts of coupons. We have \\(i\\) spots, and 3 of coupon #1, so there are \\({i \\choose 3}\\) ways to pick where the first kind of coupon go. After these are assigned, there are \\(i - 3\\) spots remaining, so there are \\({i - 3 \\choose 1}\\) ways to assign the singular coupon #5 to a spot. Following this reasoning will yield \\({i - 4 \\choose 7}\\) and \\({i - 11 \\choose i - 11}\\) as the remaining ways to assign the final two types of coupons. Multiplying all of these “choose” operations gives us the total ways to assign the coupons.\n\\[\\begin{align*}\n    {i \\choose 3} \\cdot {i - 3 \\choose 1} \\cdot {i - 4 \\choose 7} \\cdot {i - 11 \\choose i - 11}\n    &= \\frac{i!}{(i - 3)!3!} \\cdot \\frac{(i - 3)!}{(i - 4)!1!} \\cdot \\frac{(i - 4)!}{(i - 11)!7!}\n       \\cdot \\frac{(i - 11)!}{0!(i - 11)!} \\\\\n    &= \\frac{i!}{3!1!7!(i - 11)!}\n\\end{align*}\\]\nThe result is just the total ways you can arrange \\(i\\) distinct coupons (suppose coupons of the same type were somehow distinguishable), divided by the number of ways a given ordering is duplicated because coupons of the same type are not actually meaningfully distinguishable.\n\n\nNow, suppose we expanded the polynomial above fully. The terms where all \\(x_j\\) are raised to a power \\(\\ge K\\) represent successfully collecting \\(K\\) sets of all \\(n\\) coupons. If we remove all terms representing completed sets, then we are left with only incomplete collections. We can denote this removal process with the notation \\(\\{(x_1 + \\ldots + x_n)^i\\}_K\\). “The Double Dixie Cup Problem” [1] defines this formally:\n\nIf \\(P(x_1, \\ldots, x_n)\\) is a polynomial or power series we define \\(\\{P(x_1, \\ldots, x_n)\\}_K\\) to be the polynomial, or series, resulting when all terms having all exponents \\(\\ge K\\) have been removed.\n\nNow, note that if we evaluate \\(\\{(x_1 + \\ldots + x_n)^i\\}_K\\) at \\(x_1 = \\ldots = x_n = 1\\), we get a number that represents the number of draws that result in incomplete collections. Further, \\(\\frac{\\{(x_1 + \\ldots + x_n)^i\\}_K}{n^i}\\) evaluated at all 1’s is just the probability that we fail to complete \\(K\\) collections in \\(i\\) draws, or \\(p_i\\). This takes us a step forward in our expectation calculation.\n\\[\\begin{align*}\n    E_K[T]\n    &= \\sum_{i = 0}^\\infty p_i \\\\\n    &= \\sum_{i = 0}^\\infty \\frac{\\{(x_1 + \\ldots + x_n)^i\\}_K}{n^i}\n\\end{align*}\\]\nBut finding a way to evaluate the summand is not immediately obvious. To do this, we must find something we do know that looks similar to the above form, namely the exponential Power Series. As a reminder, the exponential power series is:\n\\[\\begin{align*}\n    e^x\n    &= \\sum_{i = 0}^\\infty \\frac{x^i}{i!}\n\\end{align*}\\]\nThis is the one-variable case, but to match the form of our previous work, we can use the generalized form which looks like:\n\\[\\begin{align*}\n    e^{x_1 + \\ldots + x_n}\n    &= \\sum_{i = 0}^\\infty \\frac{(x_1 + \\ldots + x_n)^i}{i!}\n\\end{align*}\\]\nWe’re getting closer, but we still need to encapsulate the polynomial in the \\(\\{\\cdot\\}_K\\) operator. To do this requires a little leap of faith. Using exponent rules and the single-variable exponential power series, we can equivalently find that:\n\\[\\begin{align*}\n    e^{x_1 + \\ldots + x_n}\n    &= e^{x_1}\\cdots e^{x_n} \\\\\n    &= \\bigg( 1 + x_1 + \\frac{x_1^2}{2!} + \\ldots \\bigg) \\cdots\n       \\bigg( 1 + x_n + \\frac{x_n^2}{2!} + \\ldots \\bigg)\n\\end{align*}\\]\nWhat we can gleam from this is that in this polynomial expansion, you are picking how many coupons were drawn of each type, instead of fixing a number of draws \\(i\\) like we did previously. If we ignore the coefficients for now and just focus on the \\(x_j\\)’s, we can see how for any possible combination of coupons you can think of, there is a way to get that combination by picking the correct term in each of the \\(n\\) power series expansions.\nThinking in the same vein, we can represent all the successful ways of achieving \\(K\\) complete sets by only including part of the taylor series expansions for each of the \\(e^{x_j}\\) terms. The part of the taylor series expansions that yield all the complete collections is:\n\\[\\begin{align*}\n    \\bigg( \\frac{x_1^K}{K!} + \\frac{x_1^{K+1}}{(K+1)!} + \\ldots \\bigg) \\cdots\n    \\bigg( \\frac{x_n^K}{K!} + \\frac{x_n^{K+1}}{(K+1)!} + \\ldots \\bigg)\n\\end{align*}\\]\nWhichever term you pick from each expansion, the exponent will always be at least \\(K\\), which means each term represents a different way to complete \\(K\\) sets of coupons. Since \\(p_i\\) represents the probability of failure, we want to get rid of these terms that represent successes. Doing just that and simplifying a little leaves us with:\n\\[\\begin{align*}\n    F\n    &= e^{x_1 + \\ldots + x_n}\n    - \\bigg( \\frac{x_1^K}{K!} + \\frac{x_1^{K+1}}{(K+1)!} + \\ldots \\bigg)\n    \\cdots \\bigg( \\frac{x_n^K}{K!} + \\frac{x_n^{K+1}}{(K+1)!} + \\ldots \\bigg) \\\\\n    &= e^{x_1 + \\ldots + x_n}\n    - \\bigg(e^{x_1} - S_K(x_1) \\bigg)\n    \\cdots \\bigg(e^{x_n} - S_K(x_n) \\bigg)\n\\end{align*}\\]\nwhere\n\\[\\begin{align*}\n    S_K(t)\n    &= \\sum_{i = 0}^{K - 1} \\frac{t^i}{i!}\n\\end{align*}\\]\nAnd by the discussion above that interpreted the subtraction of the product of the different power series expansions as removing all the scenarios that resulted in success, we claim that this expression is equal to:\n\\[\\begin{align*}\n    F\n    &= \\sum_{i = 0}^\\infty \\frac{\\{(x_1 + \\ldots + x_n)^i \\}_K}{i!}\n\\end{align*}\\]\nwhich is almost what \\(E_K[T]\\) is equal to. The only difference is that this denominator is \\(i!\\) compared to the desired \\(n^i\\). Luckily, there is an identity (that I have previously never heard of) that allows us to interchange between the two:\n\\[\\begin{align*}\n    n\\int_0^\\infty \\frac{t^i}{i!}e^{-nt} dt\n    &= \\frac{1}{n^i}\n\\end{align*}\\]\nSo, if we recall where we left off for \\(E_K[T]\\), we can plug this identity in which will allow us to use \\(F\\).\n\\[\\begin{align*}\n    E_K[T]\n    &= \\sum_{i = 0}^\\infty \\frac{\\{(x_1 + \\ldots + x_n)^i \\}_K}{n^i} \\\\\n    &= \\sum_{i = 0}^\\infty \\{(x_1 + \\ldots + x_n)^i \\}_K\n        \\left( n\\int_0^\\infty \\frac{t^i}{i!}e^{-nt} dt \\right) \\\\\n    &= n\\int_0^\\infty\\sum_{i = 0}^\\infty \\left(\n        \\frac{\\{(x_1 + \\ldots + x_n)^i \\}_K}{i!}t^i\\right)e^{-nt} dt \\\\\n    &= n\\int_0^\\infty \\left( e^{t(x_1 + \\ldots + x_n)} -\n        \\left( e^{tx_1} - S_K(tx_1) \\right) \\cdots \\left( e^{tx_n} - S_K(tx_n) \\right) \\right)e^{-nt} dt \\\\\n\\end{align*}\\]\nWe are able to switch the order of the sum and integral operators as a result of Fubini’s Theorem. Also, notice in line 3 that the summand isn’t exactly the same format that it was in \\(F\\). But this isn’t a problem because the only new term is \\(t^i\\), which appears in the power series for \\(e^t\\). The affect is that all exponents are multiplied by a factor of \\(t\\). Now, remembering that setting \\(x_1 = \\ldots = x_n = 1\\) effectively calculates the ratio of incomplete collections to possible collections, we can simplify the above equation dramatically.\n\\[\\begin{align*}\n    E_K[T]\n    &= n\\int_0^\\infty \\left( e^{tn} -\n        \\left( e^{t} - S_K(t) \\right)^n \\right)e^{-nt} dt \\\\\n    &= n\\int_0^\\infty 1 -\n        \\left( e^{t} - S_K(t) \\right)^ne^{-nt} dt \\\\\n    &= n\\int_0^\\infty 1 -\n        \\left( 1 - S_K(t)e^{-t} \\right)^n dt\n\\end{align*}\\]\nAnd that’s it! It’s okay to be a little bit unsatisfied at this answer since it does contain an integral that isn’t solvable by hand (to my knowledge). However, in the following code block, we will be looking at how we can use Python to get more concrete answers for some small examples.\n\nimport numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nfactorial = np.vectorize(np.math.factorial)\n\ndef S(K, t):\n    arr = np.arange(K)\n    return np.sum(np.power(t, arr) / factorial(arr))\n\ndef integrand(t, K, n):\n    return 1 - (1 - S(K, t) * np.exp(-t))**n\n\nn_range = np.arange(1, 11)\nK_range = np.arange(1, 11)\nresults = np.empty((n_range.size, K_range.size))\n\nfor n in n_range:\n    for K in K_range:\n        result, err = integrate.quad(integrand, 0, np.inf, args=(K, n))\n        results[n - 1, K - 1] = n * result\n\nfig, ax = plt.subplots()\n\nsns.heatmap(results, cmap='coolwarm', square=True, fmt='.1f', annot=True, \n            annot_kws={\"size\": 10}, ax=ax)\n\nax.set_title(\"Generalized Coupon Collector Problem\")\nax.set_xlabel(\"K\")\nax.set_ylabel(\"n\", rotation=0)\nax.set_xticklabels(K_range)\nax.set_yticklabels(n_range, rotation=0)\n\nfig.set_size_inches(8, 8)\nplt.show()"
  },
  {
    "objectID": "posts/dfs/index.html",
    "href": "posts/dfs/index.html",
    "title": "Riddle me this",
    "section": "",
    "text": "I’m known for my puzzles, my tricky ways,\nA challenge for Batman, every day.\nA question mark symbol, I often display,\nMy true identity, what do you say?\nSay hello to Riddler. Riddler is a project that aims to apply the “moneyball” approach to Daily Fantasy Sports (DFS). Using historical results, I believe I can algorithmically find the profit- maximizing entries into paid competitions. I plan on periodically creating blog posts to document my research and progress.\nFirst, you might be wondering why I decided to call it Riddler in the first place. Besides my love for riddles and puzzles, it is an acronym for how I would best describe this project\nThe goal of this post is to introduce the problem and outline the research plan and challenges that I anticipate will arise in the development of Riddler. I’ve broken up the development of Riddler into four parts: Optimization, Game Theory, Backtesting, and Extra Considerations."
  },
  {
    "objectID": "posts/dfs/index.html#introduction",
    "href": "posts/dfs/index.html#introduction",
    "title": "Riddle me this",
    "section": "Introduction",
    "text": "Introduction\nIn DFS, you pick a lineup of players each day. These players earn fantasy points depending on their real-world performance that day. There is no commitment like traditional fantasy sports, so you are able to place new and independent bets on the following day. There are many different contest types and styles, each of which has different payoffs, number of competitors, player pools, and more. The different contest types are:\n\n\n\nContest Type\nDescription\n\n\n\n\nTournaments\nSmall & Large field contests with HUGE prizes\n\n\nHead to Head\nFace-off against one opponent; winner takes all\n\n\n50/50s\nLand in the top half of the field and win cash\n\n\nDouble Ups\nWin and double your entry fee\n\n\nMultipliers\nMultiply your entry fee up to 11x when you win\n\n\nSatellites & Qualifiers\nWin your way into higher stakes contests\n\n\n\nAnd the different contest styles are:\n\n\n\n\n\n\n\nContest Style\nDescription\n\n\n\n\nClassic\nCreate an 8-player lineup while staying under the $50,000 salary cap. Includes Late Swap.\n\n\nShowdown Captain Mode\nCreate your team from 1 game, while staying under the $50,000 salary cap\n\n\nTiers\nOur no-salary format gets you in the game quicker – select one player from each tier\n\n\nIn-Game Showdown\nDraft your showdown team for a portion of a game\n\n\nSnake\nSnake draft a 7-player lineup\n\n\nSnake Showdown\nSnake draft a 4-player lineup\n\n\n\nMixing and matching types and styles allows you to come up with situational competitions where certain strategies could prove to be beneficial. Your choice of which competition to play in likely will have large effects on your performance and variance as a bettor."
  },
  {
    "objectID": "posts/dfs/index.html#optimization",
    "href": "posts/dfs/index.html#optimization",
    "title": "Riddle me this",
    "section": "Optimization",
    "text": "Optimization\nOptimization is the core problem. The high-level idea is that Riddler should return the lineup that expects the highest monetary return given a contest structure and player pool.\nDepending on the type and style of a competition, you might have different goals. From an optimization perspective, this translates to changing your optimization objective. Some objectives that might be intuitive include:\n\nMaximizing Expected Value\n\nCould be useful for Head to Head competitions because there is only one opponent. Since you only care about the chances that you score higher than one other person, variance might not matter as much – if you lose, you don’t care how much you lose by. We are risk-netural in this scenario.\n\nMaximizing Expected Value + k Standard Deviations\n\nCould be useful for Tournaments or Multiplier competitions because we need a really good outcome to beat the large number of competitors. High expected value might improve probability that we are in top 10%, but to maximize the chances we are in top 1%, we should also maximize variance/standard deviation. We are risk-seeking in this scenario.\n\nMaximizing Expected Value\n\nCould be useful for 50/50s or Double Ups because we want to minimize the chance we land outside the top ~50% of entries. This type of optimization is known as Mean-Variance Optimization, and is a well-stuided topic in portfolio management. We are risk-averse in this scenario."
  },
  {
    "objectID": "posts/dfs/index.html#game-theory",
    "href": "posts/dfs/index.html#game-theory",
    "title": "Riddle me this",
    "section": "Game Theory",
    "text": "Game Theory\nGiven someway to optimize our lineups, the next question is how do we come up with a complex strategy that optimizes our expected return? Some contests allow for multiple entries, whereas some only allow one entry. How do we determine the value of submitting another marginal lineup?\nAdditionally, each contest has an upfront cost. Given a fixed bankroll, how much should we bet on each lineup? Riddler could either choose some fixed amount for each lineup, or make bigger bets on lineups it is more confident about. Do concepts like the Kelly Criterion come into play here (given that our win probability is not well-known)?\nThe questions I ask here are only a few of the considerations that need to be made when selecting a strategy. It should be clear now that simply optimizing a lineup according to a metric is only part of the problem. Because we really care about our overall success, we might not necessarily want to submit a lineup that has the highest expected value on its own; instead, the lineup that maximizes the expected value of our cumulative performance on the day might be preferable."
  },
  {
    "objectID": "posts/dfs/index.html#backtesting",
    "href": "posts/dfs/index.html#backtesting",
    "title": "Riddle me this",
    "section": "Backtesting",
    "text": "Backtesting\nBefore deploying a strategy, I’d ideally want to know ahead of time how much conviction I should have that it will actually work. This is where backtesting comes in. Here we’d want to use historical data to see how well our strategy would have performed in past competitions.\nThere are a myriad of issues that I foresee in this step due to some of the struggles I have already encountered. The most pressing matter is that I’m unable to find an extensive database of past results. Websites like RotoGrinders have results databases, but only for the past couple of years, even though contests had been running for many years prior. Additionally, a common struggle in backtesting is avoiding lookahead bias. Lookahead bias is when future information is used to make decisions. While it might seem obvious that this is a bad idea, in development settings, it is easy to accidentally use data that wouldn’t have existed at the time of your simulation. One situation that will require special attention to detail is keeping track of stats. Any simulation must keep track of running totals and averages at each point in time where a decision is being made instead of using the full season worth of stats that take into account games that they had not yet played."
  },
  {
    "objectID": "posts/dfs/index.html#extra-considerations",
    "href": "posts/dfs/index.html#extra-considerations",
    "title": "Riddle me this",
    "section": "Extra Considerations",
    "text": "Extra Considerations\nThis section aims to capture everything else that could present a challenge in the development of Riddler. The main topic of this section is developing estimates for player expected values and variances. There are a couple of naive approaches you could use like cumulative or rolling means, but its hard to quantify which one of these best captures what’s likely to happen in the next game. This could get very advanced and we could start examining specific matchups, days of rest in between games and past performance against a team. However, in an aim to focus on the optimal lineups and not to invent a new projection system, my goal is to find a projection that is “good enough.”\nAdditionally, real-time challenges are likely to pop-up. A real-time challenge may include an injury or trade. An injury is likely to effect the other teammates, but disproportinately. If a starting center got hurt, the backup center would stand to gain the most, whereas the backup point guard might not change in value too much. Trades also pose issues because its hard to predict new team dynamics without any historical data. Specifically, in optimization methods that rely on covariances between players, Riddler will have to completely guess the chemistry between players on the first game they play together. It could even be a good idea to just avoid games featuring a new player all together.\nEven though I just mentioned a few ideas, the takeaway from this section is that the data is bound to get messy, so the deployed strategy must not be exploitable in the face of these challenges."
  },
  {
    "objectID": "posts/dfs/index.html#conclusion",
    "href": "posts/dfs/index.html#conclusion",
    "title": "Riddle me this",
    "section": "Conclusion",
    "text": "Conclusion\nWith a roadmap in place, I anticipate the development of Riddler. There are many challenges ahead that I’ve never encountered before that I hope to learn from. As the ‘E’ in Riddler suggests, this project is economically-motivated. I do want to make money from this endeavor, and I truly believe there is money to be made if this is done correctly. With that said, I am happy to be sharing everything that I go over publicly. Even though I’m leaking alpha, I am rewarded by the chance to have my hard-work be recognized and studied. Excited for what’s to come and hope you are too."
  },
  {
    "objectID": "posts/research-archives/index.html",
    "href": "posts/research-archives/index.html",
    "title": "Research Archives",
    "section": "",
    "text": "Papers\n\n\n\nPaper Name\nTopic\nRead?\nCitation\nNotes\n\n\n\n\nComputer Poker: A review\nPoker\nNo\n[1]\nEffective Hand Strength (EHS) Algorithm\n\n\nModifying Variability and Correlations in Winner-Take-All Contests\nGame Theory\nYes\n[2]\nHas applications in Riddler Game Theory Section\n\n\nOptimization Methods in Finance\nPortfolio Management\nParts\n[3]\npg. 143 Mean-Variance Optimization. Related to my quant stack exchange post\n\n\n\n\n\nWebsites\n\n\n\nTitle\nTopic\nRead?\nLink\nNotes\n\n\n\n\nDetermining Mean-Variance Efficient Portfolios Using Matrix Algebra\nPortfolio Management\nNo\n\n\n\n\ncvxpy Quadratic Programming\nOptimization\nYes\n\nMean-Variance Optimization\n\n\n\n\n\n\n\n\nReferences\n\n[1] J. Rubin, I. Watson, Computer poker: A review, Artificial Intelligence. 175 (2011) 958–987. https://doi.org/https://doi.org/10.1016/j.artint.2010.12.005.\n\n\n[2] A. Gaba, I. Tsetlin, R.L. Winkler, Modifying variability and correlations in winner-take-all contests, Operations Research. 52 (2004) 384–395. http://www.jstor.org/stable/30036590 (accessed February 10, 2023).\n\n\n[3] G. Cornuéjols, J. Peña, R. Tütüncü, Optimization methods in finance, Cambridge University Press, 2018. https://web.math.ku.dk/~rolf/CT_FinOpt.pdf."
  }
]