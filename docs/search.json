[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ethan Orlowsky",
    "section": "",
    "text": "Posts\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\nExtreme Couponing\n\n\nCoupon Collector’s Problem Generalized to K sets of coupons\n\n\n\n\nprobability\n\n\n \n\n\n\n\nJan 23, 2023\n\n\n11 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/coupon-collector/index.html",
    "href": "posts/coupon-collector/index.html",
    "title": "Extreme Couponing",
    "section": "",
    "text": "The traditional coupon collector’s problem asks the following question:\n\nIf there are n different kinds of coupons, and all coupons have the same probability of being drawn, how many coupons do you expect to draw with replacement to collect all kinds of coupons?\n\nWikipedia has a good explanation, so I will use that as a template for my calculation.\nLet \\(T\\) be the random variable representing the number of coupons we draw before collecting the entire set of coupons. We can decompose \\(T\\) into the sum of \\(n\\) random variables, \\(t_i\\), where \\(t_i\\) is the number of coupons drawn to get the \\(i^{th}\\) distinct coupon after \\(i - 1\\) distinct coupons have already been drawn.\n\\[\\begin{align*}\n    T = t_1 + t_2 + \\ldots + t_n\n\\end{align*}\\]\n\n\n\n\n\n\nNote\n\n\n\nA common mistake is to decompose \\(T\\) into random variables \\(t_i\\), where \\(t_i\\) represents the number of coupons drawn to collect coupon \\(i\\).\nThis is incorrect because we are likely going to be double-counting coupon draws. Let’s look at a simple example where \\(n = 2\\), and we draw coupon \\(1\\), then coupon \\(2\\). This method would set \\(t_1 = 1\\), \\(t_2 = 2\\), and \\(T = 3\\). Obviously this isn’t correct, but it’s easily mistakable when you haven’t seen the right way to approach the problem first.\n\n\nUsing Linearity of Expectation, we can separate our problem into simpler subproblems.\n\\[\\begin{align*}\n    E[T]\n    &= E[t_1 + t_2 + \\ldots + t_n] \\\\\n    &= E[t_1] + t_2 + \\ldots + E[t_n]\n\\end{align*}\\]\nNow the problem is finding what the general solution is for a number of the form \\(E[t_i]\\). \\(E[t_i]\\) captures the expected number of coupon draws to get the \\(i^{th}\\) distinct coupon after \\(i - 1\\) distinct coupons have already been drawn. We know that if \\(i - 1\\) out of \\(n\\) coupons have been drawn already, there are \\(n - i + 1\\) remaining coupons we still need to draw. So the probability we draw a new coupon is \\(\\frac{n - i + 1}{n}\\). \\(t_i\\) is satisfied on the first such success, so it has a Geometric Distribution. The expected value of a geometric random variable is \\(\\frac{1}{p}\\), or in our case, \\(\\frac{n}{n - i + 1}\\). We can now go back and solve for \\(E[T]\\).\n\\[\\begin{align*}\n    E[T]\n    &= E[t_1 + t_2 + \\ldots + t_n] \\\\\n    &= E[t_1] + E[t_2] + \\ldots + E[t_n] \\\\\n    &= \\frac{n}{n} + \\frac{n}{n - 1} + \\ldots + \\frac{n}{1} \\\\\n    &= n \\left( \\frac{1}{1} + \\frac{1}{2} + \\ldots + \\frac{1}{n} \\right) \\\\\n    &= n H_n\n\\end{align*}\\]\nwhere \\(H_n\\) is the \\(n^{th}\\) Harmonic Number. The harmonic numbers don’t have a closed form solution, but we can easily calculate them for small enough \\(N\\). We can visualize our solution using Python.\n\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nN = 50\n\ndef harmonic(n):\n    return sum(1 / i for i in range(1, n + 1))\n\nexpectations = [n * harmonic(n) for n in range(N)]\n\nplt.plot(range(1, N + 1), expectations)\nplt.gca().set(title=\"Coupon Collector's Problem\",\n              xlabel='N', \n              ylabel='Expected Draws')\nplt.show()"
  },
  {
    "objectID": "posts/coupon-collector/index.html#generalizing-to-k-sets-of-coupons",
    "href": "posts/coupon-collector/index.html#generalizing-to-k-sets-of-coupons",
    "title": "Extreme Couponing",
    "section": "Generalizing to K sets of Coupons",
    "text": "Generalizing to K sets of Coupons\nA natural extension to this warmup is asking how things change when we need to collect K of each coupon. Unfortunately, we need to take a completely different approach than we did for the case of \\(K = 1\\). We must now leverage combinatorics.\nFirst, let’s define a few terms. We are trying to find the expected number of coupons we must draw before getting \\(K\\) of each, or \\(E_K[T]\\). \\(T\\) takes on integer values, so we can rewrite our expectation as:\n\\[\\begin{align*}\n    E_K[T]\n    &= \\sum_{i=0}^\\infty i \\cdot P(T = i) \\\\\n    &= P(T = 1) + 2 \\cdot P(T = 2) + 3 \\cdot P(T = 3) + \\ldots \\\\\n    &= P(T = 1) + P(T = 2) + P(T = 3) + \\ldots \\\\\n    & \\hspace{54pt} + P(T = 2) + P(T = 3) + \\ldots \\\\\n    & \\hspace{107pt} + P(T = 3) + \\ldots \\\\\n    & \\hspace{160pt} + \\ldots \\\\\n    &= P(T > 0) + P(T > 1) + P(T > 2) + \\ldots \\\\\n    &= \\sum_{i = 0}^\\infty P(T > i) \\\\\n    &= \\sum_{i = 0}^\\infty p_i\n\\end{align*}\\]\nwhere \\(p_i = P(T > i)\\). The interpretation of \\(p_i\\) is the probability that we fail to collect \\(K\\) complete sets in \\(i\\) draws. Since there are \\(n\\) different kinds of coupons, there are \\(n^i\\) ways to draw \\(i\\) coupons. All the possible ways to draw these coupons can be represented as the polynomial:\n\\[\\begin{align*}\n    (x_1 + \\ldots + x_n)^i\n\\end{align*}\\]\nIf we were to expand this polynomial, each term would represent a combination of possible draws. For example, one of the terms in the expansion would be \\(x_1^3x_5x_9^7x_{12}^{i - 11}\\). This term represents the event of pulling 3 of coupon #1, 1 of coupon #5, 7 of coupon #9, and the remaining \\(i - 11\\) being coupon #12. Of course there are multiple ways (permutations) to pull this combination of coupons, so there would also be a coefficient on the term indicating how many ways this can be done.\n\n\n\n\n\n\nNote\n\n\n\nThough not core to the problem at hand, we can quickly discuss what that coefficient would be. Sticking with our previous example of \\(x_1^3x_5x_9^7x_{12}^{i - 11}\\), we start by thinking about how we can assign an order for these given amounts of coupons. We have \\(i\\) spots, and 3 of coupon #1, so there are \\({i \\choose 3}\\) ways to pick where the first kind of coupon go. After these are assigned, there are \\(i - 3\\) spots remaining, so there are \\({i - 3 \\choose 1}\\) ways to assign the singular coupon #5 to a spot. Following this reasoning will yield \\({i - 4 \\choose 7}\\) and \\({i - 11 \\choose i - 11}\\) as the remaining ways to assign the respective coupons. Multiplying all of these “choose” operations gives us the total ways to assign the coupons.\n\\[\\begin{align*}\n    {i \\choose 3} \\cdot {i - 3 \\choose 1} \\cdot {i - 4 \\choose 7} \\cdot {i - 11 \\choose i - 11}\n    &= \\frac{i!}{(i - 3)!3!} \\cdot \\frac{(i - 3)!}{(i - 4)!1!} \\cdot \\frac{(i - 4)!}{(i - 11)!7!}\n       \\cdot \\frac{(i - 11)!}{0!(i - 11)!} \\\\\n    &= \\frac{i!}{3!1!7!(i - 11)!}\n\\end{align*}\\]\nThe result is just the total ways you can arrange \\(i\\) distinct coupons (suppose coupons of the same type were somehow distinguishable), divided by the number of ways a given ordering is duplicated because coupons of the same type are not actually meaningfully distinguishable.\n\n\nNow, suppose we expanded the polynomial above fully. The terms where all \\(x_j\\) are raised to a power \\(\\ge K\\) represent successfully collecting \\(K\\) sets of all \\(n\\) coupons. If we remove all terms representing completed sets, then we are left with only incomplete collections. We can denote this removal process with the notation \\(\\{(x_1 + \\ldots + x_n)^i\\}_K\\). “The Double Dixie Cup Problem” [1] defines this formally:\n\nIf \\(P(x_1, \\ldots, x_n)\\) is a polynomial or power series we define \\(\\{P(x_1, \\ldots, x_n)\\}_K\\) to be the polynomial, or series, resulting when all terms having all exponents \\(\\ge K\\) have been removed.\n\nNow, note that if we evaluate \\(\\{(x_1 + \\ldots + x_n)^i\\}_K\\) at \\(x_1 = \\ldots = x_n = 1\\), we get a number that represents the number of draws that result in incomplete collections. Further, \\(\\frac{\\{(x_1 + \\ldots + x_n)^i\\}_K}{n^i}\\) evaluated at all 1’s is just the probability that we fail to complete \\(K\\) collections in \\(i\\) draws, or \\(p_i\\). This takes us a step forward in our expectation calculation.\n\\[\\begin{align*}\n    E_K[T]\n    &= \\sum_{i = 0}^\\infty p_i \\\\\n    &= \\sum_{i = 0}^\\infty \\frac{\\{(x_1 + \\ldots + x_n)^i\\}_K}{n^i}\n\\end{align*}\\]\nBut finding a way to evaluate the summand is not immediately obvious. To do this, we must find something we do know that looks similar to the above form, namely the exponential Power Series. As a reminder the power series is:\n\\[\\begin{align*}\n    e^x\n    &= \\sum_{i = 0}^\\infty \\frac{x^i}{i!}\n\\end{align*}\\]\nThis is the one-variable case, but to match the form of our previous work, we can use the generalized form which looks like:\n\\[\\begin{align*}\n    e^{x_1 + \\ldots + x_n}\n    &= \\sum_{i = 0}^\\infty \\frac{(x_1 + \\ldots + x_n)^i}{i!}\n\\end{align*}\\]\nWe’re getting closer, but we still need to encapsulate the polynomial in the \\(\\{\\cdot\\}_K\\) operator. To do this requires a little leap of faith. Using exponent rules and the single-variable exponential power series, we can equivalently find that:\n\\[\\begin{align*}\n    e^{x_1 + \\ldots + x_n}\n    &= e^{x_1}\\cdots e^{x_n} \\\\\n    &= \\bigg( 1 + x_1 + \\frac{x_1^2}{2!} + \\ldots \\bigg) \\cdots\n       \\bigg( 1 + x_n + \\frac{x_n^2}{2!} + \\ldots \\bigg)\n\\end{align*}\\]\nWhat we can gleam from this is that in this polynomial expansion, you are picking how many coupons were drawn of each type, instead of fixing a number of draws \\(i\\) like we did previously. If we ignore the coefficients for now and just focus on the \\(x_j\\)’s, we can see how for any possible combination of coupons you can think of, there is a way to get that combination by picking the correct term in each of the \\(n\\) taylor series expansions.\nThinking in the same vein, we can represent all the successful ways of achieving \\(K\\) complete sets by only including part of the taylor series expansions for each of the \\(e^{x_j}\\) terms. The part of the taylor series expansions that yield all the complete collections is:\n\\[\\begin{align*}\n    \\bigg( \\frac{x_1^K}{K!} + \\frac{x_1^{K+1}}{(K+1)!} + \\ldots \\bigg) \\cdots\n    \\bigg( \\frac{x_n^K}{K!} + \\frac{x_n^{K+1}}{(K+1)!} + \\ldots \\bigg)\n\\end{align*}\\]\nWhichever term you pick from each expansion, the exponent will always be at least \\(K\\), which means each term represents a different way to complete \\(K\\) sets of coupons. Since \\(p_i\\) represents the probability of failure, we want to get rid of these terms that represent successes. Doing just that and simplifying a little leaves us with:\n\\[\\begin{align*}\n    F\n    &= e^{x_1 + \\ldots + x_n}\n    - \\bigg( \\frac{x_1^K}{K!} + \\frac{x_1^{K+1}}{(K+1)!} + \\ldots \\bigg)\n    \\cdots \\bigg( \\frac{x_n^K}{K!} + \\frac{x_n^{K+1}}{(K+1)!} + \\ldots \\bigg) \\\\\n    &= e^{x_1 + \\ldots + x_n}\n    - \\bigg(e^{x_1} - S_K(x_1) \\bigg)\n    \\cdots \\bigg(e^{x_n} - S_K(x_n) \\bigg)\n\\end{align*}\\]\nwhere\n\\[\\begin{align*}\n    S_K(t)\n    &= \\sum_{i = 0}^{K - 1} \\frac{t^i}{i!}\n\\end{align*}\\]\nAnd by the discussion above that interpreted the subtraction of the product of the different power series expansions as removing all the scenarios that resulted in success, we claim that this expression is equal to:\n\\[\\begin{align*}\n    F\n    &= \\sum_{i = 0}^\\infty \\frac{\\{(x_1 + \\ldots + x_n)^i \\}_K}{i!}\n\\end{align*}\\]\nwhich is almost what \\(E_K[T]\\) is equal to. The only difference is that this denominator is \\(i!\\) compared to the desired \\(n^i\\). Luckily, there is an identity (that I have previously never heard of) that allows us to interchange between the two:\n\\[\\begin{align*}\n    n\\int_0^\\infty \\frac{t^i}{i!}e^{-nt} dt\n    &= \\frac{1}{n^i}\n\\end{align*}\\]\nSo, if we recall where we left off for \\(E_K[T]\\), we can plug this identity in which will allow us to use \\(F\\).\n\\[\\begin{align*}\n    E_K[T]\n    &= \\sum_{i = 0}^\\infty \\frac{\\{(x_1 + \\ldots + x_n)^i \\}_K}{n^i} \\\\\n    &= \\sum_{i = 0}^\\infty \\{(x_1 + \\ldots + x_n)^i \\}_K\n        \\left( n\\int_0^\\infty \\frac{t^i}{i!}e^{-nt} dt \\right) \\\\\n    &= n\\int_0^\\infty\\sum_{i = 0}^\\infty \\left(\n        \\frac{\\{(x_1 + \\ldots + x_n)^i \\}_K}{i!}t^i\\right)e^{-nt} dt \\\\\n    &= n\\int_0^\\infty \\left( e^{t(x_1 + \\ldots + x_n)} -\n        \\left( e^{tx_1} - S_K(tx_1) \\right) \\cdots \\left( e^{tx_n} - S_K(tx_n) \\right) \\right)e^{-nt} dt \\\\\n\\end{align*}\\]\nWe are able to switch the order of the sum and integral operators as a result of Fubini’s Theorem. Also, notice in line 3 that the summand isn’t exactly the same format that it was in \\(F\\). But this isn’t a problem because the only new term is \\(t^i\\), which appears in the power series for \\(e^t\\). The affect is that all exponents are multiplied by a factor of \\(t\\). Now, remembering that setting \\(x_1 = \\ldots = x_n = 1\\) effectively calculates the ratio of incomplete collections to possible collections, we can simplify the above equation dramatically.\n\\[\\begin{align*}\n    E_K[T]\n    &= n\\int_0^\\infty \\left( e^{tn} -\n        \\left( e^{t} - S_K(t) \\right)^n \\right)e^{-nt} dt \\\\\n    &= n\\int_0^\\infty 1 -\n        \\left( e^{t} - S_K(t) \\right)^ne^{-nt} dt \\\\\n    &= n\\int_0^\\infty 1 -\n        \\left( 1 - S_K(t)e^{-t} \\right)^n dt\n\\end{align*}\\]\nAnd that’s it! It’s okay to be a little bit unsatisfied at this answer since it does contain an integral that isn’t solvable by hand (to my knowledge). However, in the next section, we will be looking at how we can leverage Python to get more concrete answers for some example cases.\n\nimport numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nfactorial = np.vectorize(np.math.factorial)\n\ndef S(K, t):\n    arr = np.arange(K)\n    return np.sum(np.power(t, arr) / factorial(arr))\n\ndef integrand(t, K, n):\n    return 1 - (1 - S(K, t) * np.exp(-t))**n\n\nn_range = np.arange(1, 11)\nK_range = np.arange(1, 11)\nresults = np.empty((n_range.size, K_range.size))\n\nfor n in n_range:\n    for K in K_range:\n        result, err = integrate.quad(integrand, 0, np.inf, args=(K, n))\n        results[n - 1, K - 1] = n * result\n\nfig, ax = plt.subplots()\n\nsns.heatmap(results, cmap='coolwarm', square=True, fmt='.1f', annot=True, \n            annot_kws={\"size\": 10}, ax=ax)\n\nax.set_title(\"Generalized Coupon Collector Problem\")\nax.set_xlabel(\"K\")\nax.set_ylabel(\"n\", rotation=0)\nax.set_xticklabels(K_range)\nax.set_yticklabels(n_range, rotation=0)\n\nfig.set_size_inches(8, 8)\nplt.show()"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]